# -*- coding: utf-8 -*-
"""TVA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12A96A9KKZvv-sJak7dceutnjBpk24y5K
"""

!python -m spacy download en_core_web_sm
# Initialize spaCy
nlp = spacy.load("en_core_web_sm")

"""# Make sure the Excel sheet Column names are modified according to the code requirement and update your input file path accordingly"""

import pandas as pd
import spacy
import json



def extract_keyphrases(text):
    # Extract noun phrases from the given text
    doc = nlp(text)
    keyphrases = [chunk.text for chunk in doc.noun_chunks]
    return keyphrases

def subtract_question_keyphrases(answer_keyphrases, question_keyphrases):
    # Subtract question keyphrases from answer keyphrases
    return [phrase for phrase in answer_keyphrases if phrase not in question_keyphrases]

# Load the Excel file
file_path = '/content/Student_teacher _data.xlsx'
teacher_df = pd.read_excel(file_path, sheet_name='Sheet1')

# Prepare JSON output
output_json = []

# Process each row in the DataFrame
for index, row in teacher_df.iterrows():
    question_keyphrases = extract_keyphrases(row['Question'])
    teacher_keyphrases = extract_keyphrases(row['Teacher Answer'])
    student_keyphrases = extract_keyphrases(row['Student Answer'])

    # Subtract question keyphrases from teacher's and student's keyphrases
    teacher_keyphrases_subtracted = subtract_question_keyphrases(teacher_keyphrases, question_keyphrases)
    student_keyphrases_subtracted = subtract_question_keyphrases(student_keyphrases, question_keyphrases)

    # Append to output JSON
    output_json.append({
        'Question': row['Question'],
        'Teacher_Keyphrases_Excluding_Question_Keyphrases': teacher_keyphrases_subtracted,
        'Student_Keyphrases_Excluding_Question_Keyphrases': student_keyphrases_subtracted
    })

# Display the JSON output
print(json.dumps(output_json, indent=4))

import pandas as pd
import spacy
import json


def extract_keyphrases(text):
    doc = nlp(text)
    keyphrases = [chunk.text for chunk in doc.noun_chunks]
    return set(keyphrases)  # Convert list to set for later operations

def subtract_question_keyphrases(answer_keyphrases, question_keyphrases):
    return answer_keyphrases - question_keyphrases  # Set subtraction

def jaccard_similarity(set1, set2):
    intersection = set1.intersection(set2)
    union = set1.union(set2)
    return len(intersection) / len(union) if len(union) != 0 else 0

teacher_df = pd.read_excel(file_path, sheet_name='Sheet1')

# Prepare JSON output
output_json = []

# Process each question
for i, row in teacher_df.iterrows():
    question_keyphrases = extract_keyphrases(row['Question'])
    teacher_keyphrases = extract_keyphrases(row['Teacher Answer'])
    student_keyphrases = extract_keyphrases(row['Student Answer'])

    # Subtract question keyphrases from teacher's and student's keyphrases
    teacher_keyphrases_subtracted = subtract_question_keyphrases(teacher_keyphrases, question_keyphrases)
    student_keyphrases_subtracted = subtract_question_keyphrases(student_keyphrases, question_keyphrases)

    # Calculate Jaccard similarity score
    similarity_score = jaccard_similarity(teacher_keyphrases_subtracted, student_keyphrases_subtracted)

    # Append to output JSON
    output_json.append({
        'Question': row['Question'],
        'Teacher_Keyphrases_Excluding_Question': list(teacher_keyphrases_subtracted),
        'Student_Keyphrases_Excluding_Question': list(student_keyphrases_subtracted),
        'Similarity_Score': similarity_score
    })

# Display the JSON output
print(json.dumps(output_json, indent=4))

"""# If you wish to have a comparison of the keyphrases to get a score , the below cells shall be ran after running the above cell"""

!pip install sentence-transformers
from sentence_transformers import SentenceTransformer, util
import pandas as pd
import spacy

model = SentenceTransformer('all-MiniLM-L6-v2')

def extract_keyphrases(text):
    doc = nlp(text)
    keyphrases = [chunk.text for chunk in doc.noun_chunks]
    return keyphrases

def subtract_question_keyphrases(answer_keyphrases, question_keyphrases):
    return [phrase for phrase in answer_keyphrases if phrase not in question_keyphrases]

def calculate_semantic_similarity(keyphrases1, keyphrases2):
    if not keyphrases1 or not keyphrases2:
        return 0
    embeddings1 = model.encode(keyphrases1, convert_to_tensor=True)
    embeddings2 = model.encode(keyphrases2, convert_to_tensor=True)
    cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)
    max_scores = cosine_scores.max(dim=1).values  # Get the highest score for each keyphrase in keyphrases1
    average_score = max_scores.mean().item()  # Calculate the average of these maximum scores
    return average_score


teacher_df = pd.read_excel(file_path, sheet_name='Sheet1')

# Results placeholder
results = []

# Process each question
for index, row in teacher_df.iterrows():
    question_keyphrases = extract_keyphrases(row['Question'])
    teacher_keyphrases = extract_keyphrases(row['Teacher Answer'])
    student_keyphrases = extract_keyphrases(row['Student Answer'])

    # Subtract question keyphrases
    teacher_keyphrases_subtracted = subtract_question_keyphrases(teacher_keyphrases, question_keyphrases)
    student_keyphrases_subtracted = subtract_question_keyphrases(student_keyphrases, question_keyphrases)

    # Calculate semantic similarity
    similarity_score = calculate_semantic_similarity(teacher_keyphrases_subtracted, student_keyphrases_subtracted)

    results.append({
        'Question': row['Question'],
        'Similarity_Score': similarity_score
    })

# Display the results
for result in results:
    print(result)